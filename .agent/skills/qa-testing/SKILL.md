---
name: qa-testing
description: Execute manual QA testing for Auth9 features using browser automation. Automatically discovers QA documents in docs/qa/ organized by modules (tenant, user, rbac, service, invitation, session, webhook, auth), verifies scenarios with browser tests, checks Docker logs on errors, validates database state, saves detailed test reports to docs/report/. Use when the user asks to run QA tests, manual testing, verify feature functionality, or test specific modules.
---

# QA Testing Skill

Execute scenario-based manual QA testing for Auth9 using browser automation with Docker environment validation.

## Prerequisites

Before starting QA tests, verify:

1. **Docker environment is running** with all services healthy:
   - auth9-core (backend API)
   - auth9-portal (frontend)
   - auth9-keycloak (OIDC provider)
   - auth9-tidb (database)
   - auth9-redis (cache)

2. **Service URLs are accessible**:
   - Portal: http://localhost:3000
   - Auth9 Core: http://localhost:8080
   - Keycloak: http://localhost:8081

3. **Initial credentials are known**:
   - Portal Admin: admin / Admin123!
   - Keycloak Admin: admin / admin

## Workflow Overview

```
1. Confirm QA document with user
2. List all test scenarios
3. For each scenario:
   a. Execute test in browser
   b. If error occurs â†’ Check Docker logs
   c. Validate database state
   d. Record result
4. Generate test report
```

## Step 1: Discover and Confirm Test Document

**CRITICAL**: Always confirm with the user which QA document to test before starting.

### 1.1 Discover Available QA Documents

Use the Glob tool to find all QA documents:

```
Glob: docs/qa/**/*.md
```

This will return all available QA test documents in the `docs/qa/` directory, organized by modules:
- `tenant/` - Tenant management
- `user/` - User management  
- `rbac/` - Role-based access control
- `service/` - Service and client management
- `invitation/` - Invitation management
- `session/` - Session and security
- `webhook/` - Webhook management
- `auth/` - Authentication flows

Exclude `docs/qa/README.md` from the document list (it's just an index).

### 1.2 Determine User Intent

**If user request is specific** (mentions a document name, module, or topic):
- Match user's request against discovered documents
- If multiple documents match (e.g., "æµ‹è¯•ç”¨æˆ·ç®¡ç†" matches user/01-crud.md, user/02-advanced.md, user/03-validation.md), list all matches
- Confirm the matched document(s) with user
- Proceed to Step 2

**If user request is vague** (just says "run QA tests" or "test the system"):
- Read `docs/qa/README.md` to get module structure
- List all modules with document counts
- Ask user to choose which module or specific document to test

### 1.3 Confirmation Pattern

**Specific request example (single document)**:
```
User: "æŒ‰ç…§QAæ–‡æ¡£æµ‹è¯•ç”¨æˆ·CRUD @user/01-crud.md"

Agent:
âœ… å·²å‘ç°QAæ–‡æ¡£: docs/qa/user/01-crud.md
ğŸ“‹ æ–‡æ¡£æ ‡é¢˜: [ä»æ–‡æ¡£ç¬¬ä¸€è¡Œæå–]
ğŸ”¢ åœºæ™¯æ•°: 5

ç¡®è®¤å¼€å§‹æµ‹è¯•?
```

**Specific request example (module with multiple documents)**:
```
User: "æµ‹è¯•ç”¨æˆ·ç®¡ç†æ¨¡å—"

Agent:
ğŸ“‚ å·²å‘ç°ç”¨æˆ·ç®¡ç†æ¨¡å—çš„QAæ–‡æ¡£:

1. user/01-crud.md - åˆ›å»ºã€æ›´æ–°ã€ç§Ÿæˆ·å…³è” (5 ä¸ªåœºæ™¯)
2. user/02-advanced.md - åˆ é™¤ã€MFAã€åˆ—è¡¨ (5 ä¸ªåœºæ™¯)
3. user/03-validation.md - è¾¹ç•Œæµ‹è¯•ã€éªŒè¯ (3 ä¸ªåœºæ™¯)

è¯·é€‰æ‹©:
a) æµ‹è¯•å…¨éƒ¨ 3 ä¸ªæ–‡æ¡£
b) é€‰æ‹©ç‰¹å®šæ–‡æ¡£ (è¾“å…¥ç¼–å·)
```

**Vague request example**:
```
User: "è¿›è¡ŒQAæµ‹è¯•"

Agent:
ğŸ“‚ Auth9 QAæµ‹è¯•æ¨¡å—æ¦‚è§ˆ:

1. ç§Ÿæˆ·ç®¡ç† (tenant/) - 2 ä¸ªæ–‡æ¡£, 10 ä¸ªåœºæ™¯
2. ç”¨æˆ·ç®¡ç† (user/) - 3 ä¸ªæ–‡æ¡£, 13 ä¸ªåœºæ™¯
3. RBAC (rbac/) - 4 ä¸ªæ–‡æ¡£, 17 ä¸ªåœºæ™¯
4. æœåŠ¡ä¸å®¢æˆ·ç«¯ (service/) - 3 ä¸ªæ–‡æ¡£, 15 ä¸ªåœºæ™¯
5. é‚€è¯·ç®¡ç† (invitation/) - 3 ä¸ªæ–‡æ¡£, 15 ä¸ªåœºæ™¯
6. ä¼šè¯ä¸å®‰å…¨ (session/) - 4 ä¸ªæ–‡æ¡£, 20 ä¸ªåœºæ™¯
7. Webhook (webhook/) - 4 ä¸ªæ–‡æ¡£, 17 ä¸ªåœºæ™¯
8. è®¤è¯æµç¨‹ (auth/) - 5 ä¸ªæ–‡æ¡£, 23 ä¸ªåœºæ™¯

æ€»è®¡: 28 ä¸ªæ–‡æ¡£, 130 ä¸ªåœºæ™¯

è¯·é€‰æ‹©è¦æµ‹è¯•çš„æ¨¡å—æˆ–æ–‡æ¡£:
```

## Step 2: Read and Parse QA Document

Read the confirmed document and extract:
- **Database schema reference** (for validation queries)
- **Test scenarios** (numbered scenarios with sections)
- **Test data preparation SQL** (if available)

Create a scenario checklist:
```markdown
## Test Scenarios for [Document Name]
- [ ] Scenario 1: [Title]
- [ ] Scenario 2: [Title]
...
```

## Step 3: Execute Each Scenario

For each scenario, follow this pattern:

### 3.1 Pre-execution

1. **Read scenario details**:
   - Initial state requirements
   - Purpose of the test
   - Test operation steps
   - Expected results
   - Expected data state (SQL queries)

2. **Prepare test data** (if required):
   - Run preparation SQL in TiDB
   - Verify initial state

### 3.2 Browser Execution

Use the `cursor-ide-browser` MCP tools to execute UI tests:

```markdown
**Browser Test Pattern**:

1. Lock browser: browser_lock (only if tab already exists)
2. Navigate: browser_navigate to http://localhost:3000
3. Snapshot: browser_snapshot to get page structure
4. Login (if not logged in):
   - Fill username: admin
   - Fill password: Admin123!
   - Click sign in
5. Execute test steps:
   - Use browser_snapshot before each interaction
   - Use browser_click, browser_type, browser_fill
   - Wait after actions: browser_wait (1-3s incremental waits)
   - Snapshot after each action to verify result
6. Verify expected results in UI
7. Unlock browser: browser_unlock when done
```

**Important Browser Rules**:
- **Always call browser_snapshot** before interactions to get element refs
- **Use short incremental waits** (1-3s) instead of long waits
- **Check for errors** in snapshot responses
- **Never lock before navigate** - lock requires existing tab

### 3.3 Error Handling

If any step fails or shows unexpected UI state:

1. **Capture error details** from browser snapshot
2. **Check Docker logs** for the relevant service:

```bash
# Check auth9-core logs (backend API)
docker logs auth9-core --tail 50

# Check auth9-portal logs (frontend)
docker logs auth9-portal --tail 50

# Check Keycloak logs
docker logs auth9-keycloak --tail 50
```

3. **Record the error**:
   - Scenario number and name
   - Step that failed
   - Error message from UI
   - Relevant log lines from Docker
   - Timestamp

### 3.4 Database Validation

After each scenario (success or failure), validate database state:

1. **Extract validation SQL** from the scenario's "é¢„æœŸæ•°æ®çŠ¶æ€" section

2. **Execute queries using host mysql client**:

```bash
# Connect to TiDB from host
mysql -h 127.0.0.1 -P 4000 -u root auth9_db

# Or execute single query
mysql -h 127.0.0.1 -P 4000 -u root auth9_db -e "SELECT * FROM users WHERE email='test@example.com';"
```

3. **Compare actual vs expected**:
   - Count mismatches (e.g., expected 1 row, got 0)
   - Value mismatches (e.g., expected status='active', got status='pending')
   - Extra records (e.g., orphaned foreign key references)
   - Missing records (e.g., expected audit log entry)

4. **Record validation result**:
   - âœ… PASS: Data matches expected state
   - âŒ FAIL: Data mismatch (document differences)

## Step 4: Generate and Save Test Report

After all scenarios, generate a comprehensive report and save it to `docs/report/`.

### 4.1 Report File Naming

**Format**: `{qa_document_name}_result_{YYMMDD}.md`

**Examples**:
- Testing `docs/qa/user/01-crud.md` â†’ Save to `docs/report/user_01-crud_result_260202.md`
- Testing `docs/qa/tenant/01-crud.md` â†’ Save to `docs/report/tenant_01-crud_result_260202.md`
- Testing `docs/qa/rbac/02-role.md` â†’ Save to `docs/report/rbac_02-role_result_260202.md`

**File path pattern**:
```
docs/report/{module}_{document}_result_{YYMMDD}.md
```

### 4.2 Report Structure

```markdown
# QA Test Report: {Module} - {Document Title}

**Test Date**: {YYYY-MM-DD HH:mm:ss}
**QA Document**: `docs/qa/{module}/{document}.md`
**Environment**: Docker local (all services)
**Tester**: AI Agent
**Duration**: {total_time}

## Summary

| Status | Count |
|--------|-------|
| âœ… PASS | X |
| âŒ FAIL | Y |
| â­ï¸ SKIP | Z |
| **Total** | N |

**Pass Rate**: {pass_rate}%

## Detailed Results

### Scenario 1: {Title}
**Status**: âœ… PASS / âŒ FAIL
**Duration**: Xs

**Test Steps**:
- [Step 1]: âœ… Success
- [Step 2]: âœ… Success

**Database Validation**: âœ… PASS
- users table: 1 record created as expected
- audit_logs: 1 entry with correct action

---

### Scenario 2: {Title}
**Status**: âŒ FAIL
**Duration**: Xs

**Test Steps**:
- [Step 1]: âœ… Success
- [Step 2]: âŒ Failed - Error: "Email already exists"

**Error Details**:
- UI Error: "Email already exists"
- Docker Logs (auth9-core):
  ```
  [2026-02-02 10:15:32] ERROR: Duplicate key violation: users.email
  ```

**Database Validation**: âŒ FAIL
- Expected: COUNT(*) = 1
- Actual: COUNT(*) = 2 (duplicate created)

---

## Issues Summary

### ğŸ› Bug 1: {Brief Description}
**Scenario**: #{number}
**Severity**: High / Medium / Low
**Logs**: `{error message}`
**Recommendation**: {fix suggestion}

## Recommendations

{List of improvements, fixes needed, or test issues}

---

*Report generated by QA Testing Skill*
*Report saved to: `docs/report/{filename}`*
```

### 4.3 Save Report

**CRITICAL**: Always save the report to the `docs/report/` directory with the correct filename format.

Steps:
1. Generate the complete report content
2. Ensure `docs/report/` directory exists (create if needed)
3. Save with proper filename: `{module}_{document}_result_{YYMMDD}.md`
4. Confirm to user: "âœ… æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: docs/report/{filename}"

Example:
```markdown
âœ… æµ‹è¯•å®Œæˆï¼

ğŸ“Š æµ‹è¯•ç»“æœ:
- é€šè¿‡: 11/13 (84.6%)
- å¤±è´¥: 2/13 
- è·³è¿‡: 0/13

ğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: docs/report/user_01-crud_result_260202.md

âŒ å‘ç°çš„é—®é¢˜:
1. Bug #4: Connection pool exhausted (é«˜)
2. Bug #11: Keycloak sync failure (ä¸­)

ğŸ’¡ å»ºè®®: ä¿®å¤è¿æ¥æ± é…ç½®åé‡æ–°æµ‹è¯•å¤±è´¥çš„åœºæ™¯
```

## Common Database Queries

### User Management
```sql
-- Check user exists
SELECT id, email, display_name, mfa_enabled FROM users WHERE email = 'test@example.com';

-- Check tenant_users association
SELECT tu.*, t.name FROM tenant_users tu 
JOIN tenants t ON t.id = tu.tenant_id 
WHERE tu.user_id = '{user_id}';

-- Check cascade deletion
SELECT COUNT(*) FROM tenant_users WHERE user_id = '{user_id}';
SELECT COUNT(*) FROM sessions WHERE user_id = '{user_id}';
```

### Tenant Management
```sql
-- Check tenant exists
SELECT id, name, slug, status FROM tenants WHERE slug = 'test-tenant';

-- Check tenant services
SELECT * FROM services WHERE tenant_id = '{tenant_id}';
```

### RBAC
```sql
-- Check role assignment
SELECT r.name, utr.* FROM user_tenant_roles utr
JOIN roles r ON r.id = utr.role_id
WHERE utr.tenant_user_id = '{tenant_user_id}';

-- Check permissions
SELECT p.* FROM permissions p
JOIN role_permissions rp ON rp.permission_id = p.id
WHERE rp.role_id = '{role_id}';
```

## Tips for Effective Testing

1. **Test incrementally**: Don't skip scenarios - later scenarios may depend on earlier state
2. **Use browser snapshots**: Always snapshot before clicking to get correct element refs
3. **Short waits**: Use 1-3s waits after actions, check snapshot, wait more if needed
4. **Log errors immediately**: Don't wait until the end to check logs
5. **Validate data after EVERY scenario**: Even if UI looks correct, data might be wrong
6. **Reset environment**: If tests get into bad state, suggest user reset with reset-local-env skill

## Troubleshooting

### Browser automation fails
- Check if portal is accessible: `curl http://localhost:3000`
- Check auth9-portal logs: `docker logs auth9-portal`
- Try browser_navigate again with longer timeout

### Database connection fails
- Check TiDB is healthy: `docker ps | grep tidb`
- Try reconnecting to container

### Services not responding
- Check service health: `docker ps` (look for "healthy" status)
- Restart services: `docker-compose restart <service-name>`
- If persistent, suggest reset environment

## Example Usage

**User request**: "æŒ‰ç…§QAæ–‡æ¡£è¿›è¡Œç”¨æˆ·ç®¡ç†æµ‹è¯•"

**Agent response**:
1. Confirm: "è¯·ç¡®è®¤è¦æµ‹è¯• user-management.md å—?"
2. Read document
3. List 13 scenarios
4. Execute each scenario with browser + DB validation
5. Generate test report with pass/fail counts
